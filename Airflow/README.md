# ML Regression Pipeline с Apache Airflow

Проект демонстрирует создание ML pipeline для решения задачи регрессии с использованием Apache Airflow и Docker.

## Запуск проекта

1) Выбрать платформу для работы, докуда будет web-доступ по IP/домену (удаленная ВМ в Я.Облаке, локальная машина, своя ВМ, etc.)
2) Убедиться, что установлены docker и docker-compose (лучше v1)

   Пример команды установки для Ubuntu:
   ```
   apt install docker.io docker-compose
   ```
3) Стянуть этот git-проект (`git clone`), **оставаться в ветке main (!)**
4) В папке запустить проект командой `docker-compose up -d`, ждать окончания выполнения (скачка образов, сборка образа, установка зависимостей и т.д. Может занять 5-10 мин., могут быть некритические ошибки pip)
5) С помощью команды `docker ps` убедиться, что все контейнеры **up** и **healthy**, если что не так - помогает команда `docker logs`
6) Подключиться к web-интерфейсу Apache Airflow - `http://адрес_сервера:8080`, логопас по умолчанию `airflow | airflow` 
7) Поисследовать интерфейс, запустить DAG, убедиться что он отработал (зеленый цвет)

## Описание проекта

Pipeline состоит из 4 этапов обработки данных и машинного обучения:
- **Создание синтетического датасета** - генерация данных для регрессионной задачи
- **Предобработка данных** - feature engineering и нормализация
- **Обучение и валидация модели** - тренировка LinearRegression с кросс-валидацией
- **Финальная оценка модели** - расчет метрик и сохранение результатов

## Структура данных

**Датасет:**
- **1000 образцов**
- **5 базовых признаков** (feature_0 до feature_4)
- **1 целевая переменная** (непрерывные значения)
- **Дополнительные признаки:** feature_interaction, feature_squared

## Архитектура pipeline
```
create_dataset → preprocess_data → train_and_validate → evaluate_model
```

### Этапы обработки

1. **create_dataset**
    - Генерация синтетических данных через `make_regression`
    - 5 признаков, шум 0.1, random_state=42
    - Сохранение в `/tmp/regression_data.csv`

2. **preprocess_data**
    - Feature engineering (взаимодействие признаков, квадраты)
    - Стандартизация через StandardScaler
    - Сохранение обработанных данных и скейлера

3. **train_and_validate**
    - Разделение train/test (80/20)
    - Обучение LinearRegression
    - 5-fold кросс-валидация
    - Расчет MSE и R2 метрик

4. **evaluate_model**
    - Финальная оценка модели
    - Расчет MAE, MSE, R2
    - Сохранение метрик в CSV

### Результаты и артефакты

**Pipeline создает следующие файлы в /tmp/:**

- _regression_data.csv_ - исходные данные
- _preprocessed_data.csv_ - обработанные данные
- _scaler.pkl_ - сохраненный StandardScaler
- _trained_model.pkl_ - обученная модель
- _model_metrics.csv_ - финальные метрики